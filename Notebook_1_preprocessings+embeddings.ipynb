{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea8dc84f",
   "metadata": {},
   "source": [
    "# Thought process for generating the dataset using AI\n",
    "I first decided it would be best if we just had AI generate a story in the form of journal entries. Once the writing had been complete, then we could begin the process of turning it into a dataset format.  \n",
    "I found this to be a good way to go about it since machine learning models tend to have quite a few issues generating datasets. This also would allow us to create the most realistic possible dataset.  \n",
    "After research, I found the optimal size to be about 2-3 paragraphs per entry with each paragraph being between 100-200 words. \n",
    "\n",
    "\n",
    "However, journal entries aren't neatly organized academic papers with well thought out points, correct grammar, and consistency. They're quite messy. The messiness of human writing was something I had to work.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c15dccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: True\n",
      "GPU name: NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "RAW_ENTRIES_PATH = DATA_DIR / \"journal_entries_synthetic_150.json\"\n",
    "\n",
    "print(\"Using GPU:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "720b1594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "entry_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "timestamp",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "theme",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "full_text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "e95c195d-30f4-453a-ac1b-fe386b09bb25",
       "rows": [
        [
         "0",
         "1",
         "2024-01-01 00:00:00",
         "anger",
         "I got frustrated over something small today, but it spiraled into anger. I hate when I lose control like that."
        ],
        [
         "1",
         "2",
         "2024-01-02 00:00:00",
         "anxiety",
         "My mind kept looping over tiny details that shouldn't matter. It's exhausting trying to quiet the noise. There was this moment where everything felt unfair, and I snapped inside."
        ],
        [
         "2",
         "3",
         "2024-01-03 00:00:00",
         "contentment",
         "I enjoyed a quiet moment today that made me feel genuinely content. I wish those moments lasted longer."
        ],
        [
         "3",
         "4",
         "2024-01-04 00:00:00",
         "anxiety",
         "I tried grounding techniques, but the tension stayed in my chest. Maybe tomorrow will feel lighter."
        ],
        [
         "4",
         "5",
         "2024-01-05 00:00:00",
         "self_reflection",
         "I spent some time analyzing my reactions today. I realized I still repeat patterns I thought I had abandoned. I had a surprisingly peaceful day."
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>theme</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>anger</td>\n",
       "      <td>I got frustrated over something small today, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>My mind kept looping over tiny details that sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>contentment</td>\n",
       "      <td>I enjoyed a quiet moment today that made me fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>I tried grounding techniques, but the tension ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>self_reflection</td>\n",
       "      <td>I spent some time analyzing my reactions today...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entry_id  timestamp            theme  \\\n",
       "0         1 2024-01-01            anger   \n",
       "1         2 2024-01-02          anxiety   \n",
       "2         3 2024-01-03      contentment   \n",
       "3         4 2024-01-04          anxiety   \n",
       "4         5 2024-01-05  self_reflection   \n",
       "\n",
       "                                           full_text  \n",
       "0  I got frustrated over something small today, b...  \n",
       "1  My mind kept looping over tiny details that sh...  \n",
       "2  I enjoyed a quiet moment today that made me fe...  \n",
       "3  I tried grounding techniques, but the tension ...  \n",
       "4  I spent some time analyzing my reactions today...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_entries = pd.read_json(RAW_ENTRIES_PATH)\n",
    "print(df_entries.shape)\n",
    "df_entries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6274904e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x2442772c8d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\", \"tagger\"])  # keep it light\n",
    "nlp.add_pipe(\"sentencizer\")  # simple rule-based sentence splitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05b4b6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting into sentences:   0%|          | 0/150 [00:00<?, ?it/s]c:\\Users\\Daniel Mondragon\\Schoolwork\\Intro to AI\\venv\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "Splitting into sentences: 100%|██████████| 150/150 [00:00<00:00, 154.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(376, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentence_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "entry_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentence_index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentence_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "timestamp",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        }
       ],
       "ref": "6482447a-f932-478f-82b4-37ec8bf27aa9",
       "rows": [
        [
         "0",
         "1_0",
         "1",
         "0",
         "I got frustrated over something small today, but it spiraled into anger.",
         "2024-01-01 00:00:00"
        ],
        [
         "1",
         "1_1",
         "1",
         "1",
         "I hate when I lose control like that.",
         "2024-01-01 00:00:00"
        ],
        [
         "2",
         "2_0",
         "2",
         "0",
         "My mind kept looping over tiny details that shouldn't matter.",
         "2024-01-02 00:00:00"
        ],
        [
         "3",
         "2_1",
         "2",
         "1",
         "It's exhausting trying to quiet the noise.",
         "2024-01-02 00:00:00"
        ],
        [
         "4",
         "2_2",
         "2",
         "2",
         "There was this moment where everything felt unfair, and I snapped inside.",
         "2024-01-02 00:00:00"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>sentence_text</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I got frustrated over something small today, b...</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>I hate when I lose control like that.</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>My mind kept looping over tiny details that sh...</td>\n",
       "      <td>2024-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2_1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>It's exhausting trying to quiet the noise.</td>\n",
       "      <td>2024-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2_2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>There was this moment where everything felt un...</td>\n",
       "      <td>2024-01-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id  entry_id  sentence_index  \\\n",
       "0         1_0         1               0   \n",
       "1         1_1         1               1   \n",
       "2         2_0         2               0   \n",
       "3         2_1         2               1   \n",
       "4         2_2         2               2   \n",
       "\n",
       "                                       sentence_text  timestamp  \n",
       "0  I got frustrated over something small today, b... 2024-01-01  \n",
       "1              I hate when I lose control like that. 2024-01-01  \n",
       "2  My mind kept looping over tiny details that sh... 2024-01-02  \n",
       "3         It's exhausting trying to quiet the noise. 2024-01-02  \n",
       "4  There was this moment where everything felt un... 2024-01-02  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_records = []\n",
    "\n",
    "for _, row in tqdm(df_entries.iterrows(), total=len(df_entries), desc=\"Splitting into sentences\"):\n",
    "    entry_id = row[\"entry_id\"]\n",
    "    timestamp = row.get(\"timestamp\", None)\n",
    "    text = str(row[\"full_text\"])\n",
    "\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "\n",
    "    for idx, sent in enumerate(sentences):\n",
    "        sent_records.append({\n",
    "            \"sentence_id\": f\"{entry_id}_{idx}\",\n",
    "            \"entry_id\": entry_id,\n",
    "            \"sentence_index\": idx,\n",
    "            \"sentence_text\": sent,\n",
    "            \"timestamp\": timestamp,\n",
    "        })\n",
    "\n",
    "df_sentences = pd.DataFrame(sent_records)\n",
    "print(df_sentences.shape)\n",
    "df_sentences.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf60283d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Chunking sentences: 100%|██████████| 150/150 [00:00<00:00, 1426.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "chunk_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "entry_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "chunk_index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "chunk_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "timestamp",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        }
       ],
       "ref": "c17fc30e-00dd-4990-a5e0-ac17e4d80896",
       "rows": [
        [
         "0",
         "1_c0",
         "1",
         "0",
         "I got frustrated over something small today, but it spiraled into anger. I hate when I lose control like that.",
         "2024-01-01 00:00:00"
        ],
        [
         "1",
         "2_c0",
         "2",
         "0",
         "My mind kept looping over tiny details that shouldn't matter. It's exhausting trying to quiet the noise. There was this moment where everything felt unfair, and I snapped inside.",
         "2024-01-02 00:00:00"
        ],
        [
         "2",
         "3_c0",
         "3",
         "0",
         "I enjoyed a quiet moment today that made me feel genuinely content. I wish those moments lasted longer.",
         "2024-01-03 00:00:00"
        ],
        [
         "3",
         "4_c0",
         "4",
         "0",
         "I tried grounding techniques, but the tension stayed in my chest. Maybe tomorrow will feel lighter.",
         "2024-01-04 00:00:00"
        ],
        [
         "4",
         "5_c0",
         "5",
         "0",
         "I spent some time analyzing my reactions today. I realized I still repeat patterns I thought I had abandoned. I had a surprisingly peaceful day.",
         "2024-01-05 00:00:00"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>chunk_index</th>\n",
       "      <th>chunk_text</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_c0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I got frustrated over something small today, b...</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_c0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>My mind kept looping over tiny details that sh...</td>\n",
       "      <td>2024-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3_c0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>I enjoyed a quiet moment today that made me fe...</td>\n",
       "      <td>2024-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4_c0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I tried grounding techniques, but the tension ...</td>\n",
       "      <td>2024-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5_c0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>I spent some time analyzing my reactions today...</td>\n",
       "      <td>2024-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chunk_id  entry_id  chunk_index  \\\n",
       "0     1_c0         1            0   \n",
       "1     2_c0         2            0   \n",
       "2     3_c0         3            0   \n",
       "3     4_c0         4            0   \n",
       "4     5_c0         5            0   \n",
       "\n",
       "                                          chunk_text  timestamp  \n",
       "0  I got frustrated over something small today, b... 2024-01-01  \n",
       "1  My mind kept looping over tiny details that sh... 2024-01-02  \n",
       "2  I enjoyed a quiet moment today that made me fe... 2024-01-03  \n",
       "3  I tried grounding techniques, but the tension ... 2024-01-04  \n",
       "4  I spent some time analyzing my reactions today... 2024-01-05  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chunk_entry_sentences(sent_df, max_sentences=4, max_words=80):\n",
    "    \"\"\"\n",
    "    Given all sentences for one entry (sorted by sentence_index),\n",
    "    group them into chunks of up to max_sentences and max_words.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_word_count = 0\n",
    "\n",
    "    for _, row in sent_df.iterrows():\n",
    "        sent = row[\"sentence_text\"]\n",
    "        words = sent.split()\n",
    "        if not words:\n",
    "            continue\n",
    "        sent_len = len(words)\n",
    "\n",
    "        # If adding this sentence would exceed limits, start a new chunk\n",
    "        if current_chunk and (\n",
    "            len(current_chunk) >= max_sentences or current_word_count + sent_len > max_words\n",
    "        ):\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = []\n",
    "            current_word_count = 0\n",
    "\n",
    "        current_chunk.append(sent)\n",
    "        current_word_count += sent_len\n",
    "\n",
    "    # Add last chunk if non-empty\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "chunk_records = []\n",
    "\n",
    "for entry_id, group in tqdm(df_sentences.groupby(\"entry_id\"), desc=\"Chunking sentences\"):\n",
    "    group = group.sort_values(\"sentence_index\")\n",
    "    chunks = chunk_entry_sentences(group, max_sentences=4, max_words=80)\n",
    "    timestamp = group[\"timestamp\"].iloc[0] if \"timestamp\" in group.columns else None\n",
    "\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        chunk_records.append({\n",
    "            \"chunk_id\": f\"{entry_id}_c{idx}\",\n",
    "            \"entry_id\": entry_id,\n",
    "            \"chunk_index\": idx,\n",
    "            \"chunk_text\": chunk,\n",
    "            \"timestamp\": timestamp,\n",
    "        })\n",
    "\n",
    "df_chunks = pd.DataFrame(chunk_records)\n",
    "print(df_chunks.shape)\n",
    "df_chunks.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83508111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('data/sentences.parquet'), WindowsPath('data/chunks.parquet'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTENCES_PATH = DATA_DIR / \"sentences.parquet\"\n",
    "CHUNKS_PATH = DATA_DIR / \"chunks.parquet\"\n",
    "\n",
    "df_sentences.to_parquet(SENTENCES_PATH, index=False)\n",
    "df_chunks.to_parquet(CHUNKS_PATH, index=False)\n",
    "\n",
    "SENTENCES_PATH, CHUNKS_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83b0d951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel Mondragon\\Schoolwork\\Intro to AI\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Daniel Mondragon\\Schoolwork\\Intro to AI\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Embedding device: cuda\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Embedding device:\", device)\n",
    "\n",
    "embed_model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\", device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c90d9e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding sentences: 100%|██████████| 6/6 [00:01<00:00,  3.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(376, 768)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import ceil\n",
    "\n",
    "sentence_texts = df_sentences[\"sentence_text\"].astype(str).tolist()\n",
    "\n",
    "batch_size = 64\n",
    "num_batches = ceil(len(sentence_texts) / batch_size)\n",
    "sentence_embs = []\n",
    "\n",
    "for i in tqdm(range(num_batches), desc=\"Embedding sentences\"):\n",
    "    batch = sentence_texts[i*batch_size:(i+1)*batch_size]\n",
    "    emb = embed_model.encode(\n",
    "        batch,\n",
    "        batch_size=len(batch),\n",
    "        convert_to_numpy=True,\n",
    "        show_progress_bar=False\n",
    "    )\n",
    "    sentence_embs.append(emb)\n",
    "\n",
    "sentence_embs = np.vstack(sentence_embs)\n",
    "sentence_embs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3715efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding chunks: 100%|██████████| 3/3 [00:00<00:00, 12.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150, 768)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_texts = df_chunks[\"chunk_text\"].astype(str).tolist()\n",
    "\n",
    "num_batches = ceil(len(chunk_texts) / batch_size)\n",
    "chunk_embs = []\n",
    "\n",
    "for i in tqdm(range(num_batches), desc=\"Embedding chunks\"):\n",
    "    batch = chunk_texts[i*batch_size:(i+1)*batch_size]\n",
    "    emb = embed_model.encode(\n",
    "        batch,\n",
    "        batch_size=len(batch),\n",
    "        convert_to_numpy=True,\n",
    "        show_progress_bar=False\n",
    "    )\n",
    "    chunk_embs.append(emb)\n",
    "\n",
    "chunk_embs = np.vstack(chunk_embs)\n",
    "chunk_embs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12630925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('data/sentence_embeddings.npy'),\n",
       " WindowsPath('data/chunk_embeddings.npy'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENT_EMB_PATH = DATA_DIR / \"sentence_embeddings.npy\"\n",
    "CHUNK_EMB_PATH = DATA_DIR / \"chunk_embeddings.npy\"\n",
    "\n",
    "np.save(SENT_EMB_PATH, sentence_embs)\n",
    "np.save(CHUNK_EMB_PATH, chunk_embs)\n",
    "\n",
    "SENT_EMB_PATH, CHUNK_EMB_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "237942c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries: 150\n",
      "Sentences: 376\n",
      "Chunks: 150\n",
      "Sentence emb shape: (376, 768)\n",
      "Chunk emb shape: (150, 768)\n",
      "Sample entry_id: 8\n",
      "\n",
      "Original text:\n",
      "It felt like I was dragging myself through the day. Even small tasks seemed overwhelming. I felt really down today, like I was underwater emotionally.\n",
      "\n",
      "Sentences:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentence_index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentence_text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "40a5bb16-af24-4be7-9fef-578df49c7f21",
       "rows": [
        [
         "17",
         "0",
         "It felt like I was dragging myself through the day."
        ],
        [
         "18",
         "1",
         "Even small tasks seemed overwhelming."
        ],
        [
         "19",
         "2",
         "I felt really down today, like I was underwater emotionally."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>sentence_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>It felt like I was dragging myself through the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>Even small tasks seemed overwhelming.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>I felt really down today, like I was underwate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentence_index                                      sentence_text\n",
       "17               0  It felt like I was dragging myself through the...\n",
       "18               1              Even small tasks seemed overwhelming.\n",
       "19               2  I felt really down today, like I was underwate..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chunks:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "chunk_index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "chunk_text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "bdd30f98-3fb3-4b2b-b618-3614e4b1fc63",
       "rows": [
        [
         "7",
         "0",
         "It felt like I was dragging myself through the day. Even small tasks seemed overwhelming. I felt really down today, like I was underwater emotionally."
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_index</th>\n",
       "      <th>chunk_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>It felt like I was dragging myself through the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chunk_index                                         chunk_text\n",
       "7            0  It felt like I was dragging myself through the..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Entries:\", df_entries.shape[0])\n",
    "print(\"Sentences:\", df_sentences.shape[0])\n",
    "print(\"Chunks:\", df_chunks.shape[0])\n",
    "print(\"Sentence emb shape:\", sentence_embs.shape)\n",
    "print(\"Chunk emb shape:\", chunk_embs.shape)\n",
    "\n",
    "# Check a random entry → its sentences → its chunks\n",
    "sample_entry_id = df_entries[\"entry_id\"].sample(1).iloc[0]\n",
    "print(\"Sample entry_id:\", sample_entry_id)\n",
    "\n",
    "print(\"\\nOriginal text:\")\n",
    "print(df_entries.loc[df_entries[\"entry_id\"] == sample_entry_id, \"full_text\"].iloc[0])\n",
    "\n",
    "print(\"\\nSentences:\")\n",
    "display(df_sentences[df_sentences[\"entry_id\"] == sample_entry_id][[\"sentence_index\", \"sentence_text\"]])\n",
    "\n",
    "print(\"\\nChunks:\")\n",
    "display(df_chunks[df_chunks[\"entry_id\"] == sample_entry_id][[\"chunk_index\", \"chunk_text\"]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
